{"cells":[{"cell_type":"markdown","metadata":{},"source":["### **Import Pipeline from transformers to perform various Tasks**"]},{"cell_type":"markdown","metadata":{},"source":["### **Sentiment Analysis**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:49:28.121684Z","iopub.status.busy":"2025-05-27T09:49:28.121307Z","iopub.status.idle":"2025-05-27T09:49:58.401978Z","shell.execute_reply":"2025-05-27T09:49:58.401393Z","shell.execute_reply.started":"2025-05-27T09:49:28.121657Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-05-27 09:49:36.819486: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1748339376.989711      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1748339377.036653      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d2abecfa07c47dcb2ec89dcee836670","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34d88f4f03244ea0b478f044eec5102a","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a842882244ec44a5a3deea7b444fb41a","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2cc3a3c83e041dfb1cb9c1989fa3e06","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Device set to use cuda:0\n"]}],"source":["from transformers import pipeline\n","classifier=pipeline(\"sentiment-analysis\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:49:58.403570Z","iopub.status.busy":"2025-05-27T09:49:58.402945Z","iopub.status.idle":"2025-05-27T09:49:58.779397Z","shell.execute_reply":"2025-05-27T09:49:58.778676Z","shell.execute_reply.started":"2025-05-27T09:49:58.403541Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'label': 'POSITIVE', 'score': 0.9998230338096619}, {'label': 'NEGATIVE', 'score': 0.9888855218887329}]\n"]}],"source":["tasks=classifier([\n","    \"I'm learning Hugging Face course nowadays and this course is very great and i've learned a lot from this course\",\n","    \"But Balancing work and learning has been quite exhausting lately\"\n","])\n","print(tasks)"]},{"cell_type":"markdown","metadata":{},"source":["### **Check labels and their Scores**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:49:58.780399Z","iopub.status.busy":"2025-05-27T09:49:58.780135Z","iopub.status.idle":"2025-05-27T09:49:58.784603Z","shell.execute_reply":"2025-05-27T09:49:58.784057Z","shell.execute_reply.started":"2025-05-27T09:49:58.780381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels:  POSITIVE ----> Score:  0.9998230338096619\n","Labels:  NEGATIVE ----> Score:  0.9888855218887329\n"]}],"source":["for task in tasks:\n","  Labels=task[\"label\"]\n","  Scores=task[\"score\"]\n","  print(\"Labels: \",Labels, '---->', \"Score: \", Scores)"]},{"cell_type":"markdown","metadata":{},"source":["### **Initializing the Tokenizer**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:49:58.786367Z","iopub.status.busy":"2025-05-27T09:49:58.786196Z","iopub.status.idle":"2025-05-27T09:50:01.904086Z","shell.execute_reply":"2025-05-27T09:50:01.903322Z","shell.execute_reply.started":"2025-05-27T09:49:58.786353Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9cba67bc7ea44824b9eb8cbe60e49bc3","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74a9b9942e4b44a99cd60c30996639ad","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2643e78615f54d0da6d8ae2d0e200cae","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8eadb42feddb411983a9052d8c7915ea","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BertTokenizerFast(name_or_path='google-bert/bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n","\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n",")\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","tokenizer=AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n","print(tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["### **preprocessing with tokenizer**"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:01.905202Z","iopub.status.busy":"2025-05-27T09:50:01.904919Z","iopub.status.idle":"2025-05-27T09:50:01.910035Z","shell.execute_reply":"2025-05-27T09:50:01.909339Z","shell.execute_reply.started":"2025-05-27T09:50:01.905178Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[101, 146, 112, 182, 3776, 20164, 10932, 10289, 1736, 20148, 1105, 1142, 1736, 1110, 1304, 1632, 1105, 178, 112, 1396, 3560, 170, 1974, 1121, 1142, 1736, 102], [101, 1252, 18757, 24855, 1250, 1105, 3776, 1144, 1151, 2385, 16287, 1158, 10634, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}],"source":["tasks=tokenizer([\n","    \"I'm learning Hugging Face course nowadays and this course is very great and i've learned a lot from this course\",\n","    \"But Balancing work and learning has been quite exhausting lately\"\n","])\n","print(tasks)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:01.911182Z","iopub.status.busy":"2025-05-27T09:50:01.910912Z","iopub.status.idle":"2025-05-27T09:50:02.188777Z","shell.execute_reply":"2025-05-27T09:50:02.188032Z","shell.execute_reply.started":"2025-05-27T09:50:01.911161Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[101, 146, 112, 182, 3776, 20164, 10932, 10289, 1736, 20148, 1105, 1142, 1736, 1110, 1304, 1632, 1105, 178, 112, 1396, 3560, 170, 1974, 1121, 1142, 1736, 102], [101, 1252, 18757, 24855, 1250, 1105, 3776, 1144, 1151, 2385, 16287, 1158, 10634, 102]]\n"]}],"source":["print(tasks[\"input_ids\"])"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:02.189647Z","iopub.status.busy":"2025-05-27T09:50:02.189459Z","iopub.status.idle":"2025-05-27T09:50:02.201387Z","shell.execute_reply":"2025-05-27T09:50:02.200738Z","shell.execute_reply.started":"2025-05-27T09:50:02.189633Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input ids [[101, 146, 112, 182, 3776, 20164, 10932, 10289, 1736, 20148, 1105, 1142, 1736, 1110, 1304, 1632, 1105, 178, 112, 1396, 3560, 170, 1974, 1121, 1142, 1736, 102], [101, 1252, 18757, 24855, 1250, 1105, 3776, 1144, 1151, 2385, 16287, 1158, 10634, 102]]\n","keys input_ids\n","Token type ids [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","Attention Mask [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n","Input ids [[101, 146, 112, 182, 3776, 20164, 10932, 10289, 1736, 20148, 1105, 1142, 1736, 1110, 1304, 1632, 1105, 178, 112, 1396, 3560, 170, 1974, 1121, 1142, 1736, 102], [101, 1252, 18757, 24855, 1250, 1105, 3776, 1144, 1151, 2385, 16287, 1158, 10634, 102]]\n","keys token_type_ids\n","Token type ids [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","Attention Mask [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n","Input ids [[101, 146, 112, 182, 3776, 20164, 10932, 10289, 1736, 20148, 1105, 1142, 1736, 1110, 1304, 1632, 1105, 178, 112, 1396, 3560, 170, 1974, 1121, 1142, 1736, 102], [101, 1252, 18757, 24855, 1250, 1105, 3776, 1144, 1151, 2385, 16287, 1158, 10634, 102]]\n","keys attention_mask\n","Token type ids [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","Attention Mask [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"]}],"source":["for key in tasks:\n","  print(\"Input ids\", tasks[\"input_ids\"])\n","  print(\"keys\", key)\n","  print(\"Token type ids\", tasks[\"token_type_ids\"])\n","  print(\"Attention Mask\", tasks[\"attention_mask\"])"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:02.202369Z","iopub.status.busy":"2025-05-27T09:50:02.202112Z","iopub.status.idle":"2025-05-27T09:50:02.220913Z","shell.execute_reply":"2025-05-27T09:50:02.220370Z","shell.execute_reply.started":"2025-05-27T09:50:02.202347Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[  101,   146,  1198,  2063,  1139,  1148, 21239,  2101,  2235,  5438,\n","          1106,  1142,  1736,   117,  1105,  1122,  5115,  6929,   106,   102,\n","             0,     0],\n","        [  101,  1188,  1736,  1110, 15695,  1177,  1218,   117,  1122,   112,\n","           188,  1103,  1436,  3776,  2541,   146,   112,  1396,  1125,  3294,\n","           119,   102],\n","        [  101,  1109,  6418,  1110,  1315,  2698,   117,  1105,   146,  1631,\n","          2423,  1575,  1170,  1103,  1148,  1374,  8497,   119,   102,     0,\n","             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n"]}],"source":["raw_text=[\n","    \"I just completed my first NLP model thanks to this course, and it feels amazing!\",\n","    \"This course is structured so well, it's the best learning experience I've had online.\",\n","    \"The pace is too fast, and I feel completely lost after the first few lessons.\"\n","]\n","input=tokenizer(raw_text, padding=True, truncation=True, return_tensors=\"pt\")\n","print(input)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:02.221901Z","iopub.status.busy":"2025-05-27T09:50:02.221605Z","iopub.status.idle":"2025-05-27T09:50:02.231663Z","shell.execute_reply":"2025-05-27T09:50:02.230962Z","shell.execute_reply.started":"2025-05-27T09:50:02.221884Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input ids tensor([[  101,   146,  1198,  2063,  1139,  1148, 21239,  2101,  2235,  5438,\n","          1106,  1142,  1736,   117,  1105,  1122,  5115,  6929,   106,   102,\n","             0,     0],\n","        [  101,  1188,  1736,  1110, 15695,  1177,  1218,   117,  1122,   112,\n","           188,  1103,  1436,  3776,  2541,   146,   112,  1396,  1125,  3294,\n","           119,   102],\n","        [  101,  1109,  6418,  1110,  1315,  2698,   117,  1105,   146,  1631,\n","          2423,  1575,  1170,  1103,  1148,  1374,  8497,   119,   102,     0,\n","             0,     0]])\n","keys input_ids\n","Token type ids tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","Attention Mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n","Input ids tensor([[  101,   146,  1198,  2063,  1139,  1148, 21239,  2101,  2235,  5438,\n","          1106,  1142,  1736,   117,  1105,  1122,  5115,  6929,   106,   102,\n","             0,     0],\n","        [  101,  1188,  1736,  1110, 15695,  1177,  1218,   117,  1122,   112,\n","           188,  1103,  1436,  3776,  2541,   146,   112,  1396,  1125,  3294,\n","           119,   102],\n","        [  101,  1109,  6418,  1110,  1315,  2698,   117,  1105,   146,  1631,\n","          2423,  1575,  1170,  1103,  1148,  1374,  8497,   119,   102,     0,\n","             0,     0]])\n","keys token_type_ids\n","Token type ids tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","Attention Mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n","Input ids tensor([[  101,   146,  1198,  2063,  1139,  1148, 21239,  2101,  2235,  5438,\n","          1106,  1142,  1736,   117,  1105,  1122,  5115,  6929,   106,   102,\n","             0,     0],\n","        [  101,  1188,  1736,  1110, 15695,  1177,  1218,   117,  1122,   112,\n","           188,  1103,  1436,  3776,  2541,   146,   112,  1396,  1125,  3294,\n","           119,   102],\n","        [  101,  1109,  6418,  1110,  1315,  2698,   117,  1105,   146,  1631,\n","          2423,  1575,  1170,  1103,  1148,  1374,  8497,   119,   102,     0,\n","             0,     0]])\n","keys attention_mask\n","Token type ids tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","Attention Mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n"]}],"source":["for key in input:\n","  print(\"Input ids\", input[\"input_ids\"])\n","  print(\"keys\", key)\n","  print(\"Token type ids\", input[\"token_type_ids\"])\n","  print(\"Attention Mask\", input[\"attention_mask\"])"]},{"cell_type":"markdown","metadata":{},"source":["### **Initializing the AutoModelForSequenceClassification**"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:02.234415Z","iopub.status.busy":"2025-05-27T09:50:02.234165Z","iopub.status.idle":"2025-05-27T09:50:09.570216Z","shell.execute_reply":"2025-05-27T09:50:09.569677Z","shell.execute_reply.started":"2025-05-27T09:50:02.234394Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b641703d7e84bacb1c014c3918d7e25","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e273e5069b54ea286919d32ea11fbb2","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoModel, AutoModelForSequenceClassification\n","model=AutoModel.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:09.571186Z","iopub.status.busy":"2025-05-27T09:50:09.570960Z","iopub.status.idle":"2025-05-27T09:50:09.576926Z","shell.execute_reply":"2025-05-27T09:50:09.576287Z","shell.execute_reply.started":"2025-05-27T09:50:09.571160Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSdpaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{},"source":["### **Model Inference**"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:09.578340Z","iopub.status.busy":"2025-05-27T09:50:09.577637Z","iopub.status.idle":"2025-05-27T09:50:09.799377Z","shell.execute_reply":"2025-05-27T09:50:09.798749Z","shell.execute_reply.started":"2025-05-27T09:50:09.578315Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.6529, -0.0590, -0.2047,  ...,  0.0997,  0.3205,  0.4848],\n","         [-0.1749, -0.0310, -0.0763,  ..., -0.1239,  0.1651,  0.1732],\n","         [-0.3366, -0.0607,  0.4245,  ...,  0.2330,  0.1745,  0.1222],\n","         ...,\n","         [ 0.3769,  0.1352, -0.3995,  ...,  0.1589, -0.4545, -0.2293],\n","         [-0.4789, -0.1506, -0.4105,  ...,  0.1330,  0.1464,  0.1058],\n","         [-0.4601, -0.1313, -0.3631,  ...,  0.1185,  0.0938,  0.0865]],\n","\n","        [[-0.2786,  0.2764,  0.1395,  ...,  0.0683,  0.2214,  0.4002],\n","         [-0.0067,  0.4242,  0.2066,  ..., -0.0732,  0.9418,  0.9121],\n","         [ 0.1281,  0.3166,  0.2722,  ...,  0.0143,  0.1658, -0.1166],\n","         ...,\n","         [ 0.1668,  0.3143,  0.4670,  ...,  0.1749,  0.1529,  0.1949],\n","         [-0.0364, -0.3749,  0.2296,  ...,  0.0761,  0.2537, -0.0946],\n","         [ 0.3990,  0.3977, -0.3980,  ...,  0.4265, -0.7808, -0.3104]],\n","\n","        [[-0.3194,  0.1183,  0.1727,  ..., -0.0189,  0.2487,  0.5928],\n","         [ 0.3904, -0.0677,  0.5205,  ..., -0.0263,  0.2690,  0.1623],\n","         [-0.0796,  0.1259,  0.1910,  ..., -0.1504,  0.0756, -0.2399],\n","         ...,\n","         [-0.0814,  0.0475,  0.2415,  ...,  0.0776,  0.1856,  0.1053],\n","         [-0.2734, -0.0551,  0.0299,  ...,  0.2893,  0.3052,  0.0159],\n","         [-0.0940, -0.0158,  0.1269,  ...,  0.0421,  0.1383, -0.0145]]],\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7299, -0.2195, -0.0946,  ..., -0.1976, -0.4916,  0.8026],\n","        [-0.7644, -0.1380,  0.1851,  ...,  0.2660, -0.4933,  0.8014],\n","        [-0.6799, -0.1686,  0.0099,  ...,  0.0075, -0.4406,  0.6222]],\n","       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["output=model(**input)\n","output"]},{"cell_type":"markdown","metadata":{},"source":["### **Let's Check the Hidden State**"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:09.800314Z","iopub.status.busy":"2025-05-27T09:50:09.800105Z","iopub.status.idle":"2025-05-27T09:50:09.808095Z","shell.execute_reply":"2025-05-27T09:50:09.807479Z","shell.execute_reply.started":"2025-05-27T09:50:09.800299Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[[-0.6529, -0.0590, -0.2047,  ...,  0.0997,  0.3205,  0.4848],\n","         [-0.1749, -0.0310, -0.0763,  ..., -0.1239,  0.1651,  0.1732],\n","         [-0.3366, -0.0607,  0.4245,  ...,  0.2330,  0.1745,  0.1222],\n","         ...,\n","         [ 0.3769,  0.1352, -0.3995,  ...,  0.1589, -0.4545, -0.2293],\n","         [-0.4789, -0.1506, -0.4105,  ...,  0.1330,  0.1464,  0.1058],\n","         [-0.4601, -0.1313, -0.3631,  ...,  0.1185,  0.0938,  0.0865]],\n","\n","        [[-0.2786,  0.2764,  0.1395,  ...,  0.0683,  0.2214,  0.4002],\n","         [-0.0067,  0.4242,  0.2066,  ..., -0.0732,  0.9418,  0.9121],\n","         [ 0.1281,  0.3166,  0.2722,  ...,  0.0143,  0.1658, -0.1166],\n","         ...,\n","         [ 0.1668,  0.3143,  0.4670,  ...,  0.1749,  0.1529,  0.1949],\n","         [-0.0364, -0.3749,  0.2296,  ...,  0.0761,  0.2537, -0.0946],\n","         [ 0.3990,  0.3977, -0.3980,  ...,  0.4265, -0.7808, -0.3104]],\n","\n","        [[-0.3194,  0.1183,  0.1727,  ..., -0.0189,  0.2487,  0.5928],\n","         [ 0.3904, -0.0677,  0.5205,  ..., -0.0263,  0.2690,  0.1623],\n","         [-0.0796,  0.1259,  0.1910,  ..., -0.1504,  0.0756, -0.2399],\n","         ...,\n","         [-0.0814,  0.0475,  0.2415,  ...,  0.0776,  0.1856,  0.1053],\n","         [-0.2734, -0.0551,  0.0299,  ...,  0.2893,  0.3052,  0.0159],\n","         [-0.0940, -0.0158,  0.1269,  ...,  0.0421,  0.1383, -0.0145]]],\n","       grad_fn=<NativeLayerNormBackward0>)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["output.last_hidden_state"]},{"cell_type":"markdown","metadata":{},"source":["### **Loading Tokenizer and Model for Sequence Classification**"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:09.809085Z","iopub.status.busy":"2025-05-27T09:50:09.808827Z","iopub.status.idle":"2025-05-27T09:50:12.320358Z","shell.execute_reply":"2025-05-27T09:50:12.319623Z","shell.execute_reply.started":"2025-05-27T09:50:09.809069Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"852f06e78b5341f9a7dd25d56c25df33","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20cae46e9ef64e5084e7e38ecb1e901a","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d74ff64b12d4befaf60468408dde9d6","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["{'input_ids': [[101, 1045, 2074, 2949, 2026, 2034, 17953, 2361, 2944, 4283, 2000, 2023, 2607, 1010, 1998, 2009, 5683, 6429, 999, 102], [101, 2023, 2607, 2003, 14336, 2061, 2092, 1010, 2009, 1005, 1055, 1996, 2190, 4083, 3325, 1045, 1005, 2310, 2018, 3784, 1012, 102], [101, 1996, 6393, 2003, 2205, 3435, 1010, 1998, 1045, 2514, 3294, 2439, 2044, 1996, 2034, 2261, 8220, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n","SequenceClassifierOutput(loss=None, logits=tensor([[-0.1025,  0.0752],\n","        [-0.0387,  0.0399],\n","        [-0.0049,  0.1121]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"]}],"source":["new_tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","new_model=AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","print(new_tokenizer(raw_text))\n","new_output=new_model(**input)\n","print(new_output)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:12.321402Z","iopub.status.busy":"2025-05-27T09:50:12.321100Z","iopub.status.idle":"2025-05-27T09:50:12.326872Z","shell.execute_reply":"2025-05-27T09:50:12.326172Z","shell.execute_reply.started":"2025-05-27T09:50:12.321375Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-0.1025,  0.0752],\n","        [-0.0387,  0.0399],\n","        [-0.0049,  0.1121]], grad_fn=<AddmmBackward0>)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["new_output.logits"]},{"cell_type":"markdown","metadata":{"id":"7yRnNZ9B2zRB"},"source":["### **Pipeline Step#2: Models**"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:12.327752Z","iopub.status.busy":"2025-05-27T09:50:12.327558Z","iopub.status.idle":"2025-05-27T09:50:13.250458Z","shell.execute_reply":"2025-05-27T09:50:13.249858Z","shell.execute_reply.started":"2025-05-27T09:50:12.327737Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5e5f3d5180d4757acb492b530a1d3eb","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e640ff4ef0045029f45f66ddf8f75da","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Bert Config\n","BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.51.3\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","====================================\n","DistillBert Config\n","DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.51.3\",\n","  \"vocab_size\": 28996\n","}\n","\n"]}],"source":["from transformers import AutoConfig\n","bert_config=AutoConfig.from_pretrained(\"bert-base-cased\")\n","distill_bert_config=AutoConfig.from_pretrained(\"distilbert-base-cased\")\n","print(\"Bert Config\")\n","print(bert_config)\n","print(\"====================================\")\n","print(\"DistillBert Config\")\n","print(distill_bert_config)"]},{"cell_type":"markdown","metadata":{},"source":["### **Build and Initiate Bert Model**"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:13.251951Z","iopub.status.busy":"2025-05-27T09:50:13.251730Z","iopub.status.idle":"2025-05-27T09:50:15.024424Z","shell.execute_reply":"2025-05-27T09:50:15.023825Z","shell.execute_reply.started":"2025-05-27T09:50:13.251934Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.6193,  0.2607,  0.6255,  ..., -0.7153,  0.6707,  0.0764],\n","         [-2.0228, -0.4286, -0.5066,  ..., -0.6277,  0.9974,  0.0740],\n","         [-0.9703,  0.2473,  1.0533,  ..., -0.4428,  1.2016,  0.0530],\n","         ...,\n","         [-2.1384, -0.4949,  1.2165,  ..., -1.0511,  1.6720,  0.4441],\n","         [-0.0434, -0.8210,  0.8945,  ..., -0.7165,  0.6419, -0.4592],\n","         [-0.6590,  1.0525,  0.0972,  ..., -1.0746,  0.9174,  0.4342]],\n","\n","        [[-1.6281, -0.1704, -1.1188,  ..., -0.2858, -0.2713,  0.2564],\n","         [-0.6740, -0.3164, -0.4970,  ...,  0.5964, -0.0354, -0.8318],\n","         [-1.8225,  0.7726, -0.8557,  ..., -0.1075, -0.2066, -0.0195],\n","         ...,\n","         [-1.3776, -0.7317,  0.5135,  ..., -2.1974,  1.2533, -0.0741],\n","         [ 0.7745,  0.8303, -1.0872,  ..., -0.7140,  1.3697, -0.7209],\n","         [-0.2268,  1.2647,  0.5741,  ..., -1.8204,  0.2144,  0.2123]],\n","\n","        [[-1.2001, -0.2097,  1.1359,  ..., -0.4098, -0.0592, -0.0061],\n","         [-2.3846, -1.0305,  1.1401,  ..., -0.2146, -1.1821, -0.5952],\n","         [-0.6078,  0.0204,  1.8500,  ..., -0.8057,  0.1397, -0.1064],\n","         ...,\n","         [-1.2039, -0.5355,  0.3884,  ..., -1.3036,  0.6576,  0.2028],\n","         [-0.6550,  0.0491,  0.7739,  ..., -1.0635,  1.0401, -0.3319],\n","         [-1.5049,  1.0998, -0.1026,  ..., -1.2426,  0.2622, -0.2166]]],\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.2096,  0.7930,  0.1453,  ...,  0.8005, -0.1111,  0.1434],\n","        [ 0.4206,  0.5798,  0.2216,  ...,  0.4786, -0.1882,  0.1278],\n","        [-0.3264,  0.8097,  0.3212,  ...,  0.2653, -0.2820,  0.1501]],\n","       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"]}],"source":["from transformers import BertConfig, BertModel\n","# building the config\n","bert_model_config=BertConfig()\n","# initiate the model\n","new_bert_model=BertModel(bert_model_config)\n","output=new_bert_model(**input)\n","print(output)"]},{"cell_type":"markdown","metadata":{},"source":["### **Bert Model Configuration**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:15.025333Z","iopub.status.busy":"2025-05-27T09:50:15.025138Z","iopub.status.idle":"2025-05-27T09:50:15.031081Z","shell.execute_reply":"2025-05-27T09:50:15.030494Z","shell.execute_reply.started":"2025-05-27T09:50:15.025318Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertConfig {\n","  \"_attn_implementation_autoset\": true,\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.51.3\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["bert_model_config"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:15.032664Z","iopub.status.busy":"2025-05-27T09:50:15.032446Z","iopub.status.idle":"2025-05-27T09:50:18.854501Z","shell.execute_reply":"2025-05-27T09:50:18.853746Z","shell.execute_reply.started":"2025-05-27T09:50:15.032649Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99ab86f7336743dc99300706440d5d0f","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4253,  0.3248,  0.0430,  ..., -0.2575,  0.3103,  0.1707],\n","         [ 0.5382, -0.1613,  0.6989,  ..., -0.0964, -0.0568,  0.3808],\n","         [ 0.2170,  0.2973,  0.5711,  ..., -0.2103,  0.0724,  0.7651],\n","         ...,\n","         [ 0.5229,  0.6780,  0.5030,  ..., -0.0231,  0.4312,  0.1336],\n","         [ 0.0116,  0.4218,  0.1210,  ...,  0.2599,  0.1712,  0.2193],\n","         [-0.0762,  0.2327,  0.3460,  ...,  0.0439,  0.3603,  0.1510]],\n","\n","        [[ 0.6200,  0.2703, -0.0238,  ..., -0.2052,  0.2143,  0.2290],\n","         [ 0.4604, -0.3071,  0.6603,  ..., -0.2155,  0.2643,  0.4050],\n","         [ 0.1338,  0.3411,  0.2855,  ..., -0.0541, -0.2121,  0.4941],\n","         ...,\n","         [ 0.1254,  0.1800,  0.6234,  ...,  0.3937,  0.0403,  0.1280],\n","         [ 0.7558,  1.1082, -0.0067,  ..., -0.0597,  0.1057, -0.0213],\n","         [ 0.6842,  1.1525,  0.0021,  ..., -0.0347,  0.0960,  0.0695]],\n","\n","        [[ 0.3652,  0.1974, -0.1084,  ..., -0.2368,  0.1061,  0.1169],\n","         [ 0.2221, -0.4938,  0.5226,  ..., -0.1244, -0.0099,  0.2656],\n","         [-0.1185,  0.3595,  0.0441,  ..., -0.0539, -0.1705,  0.0875],\n","         ...,\n","         [-0.3045,  0.3797, -0.0865,  ...,  0.1314,  0.0196,  0.3383],\n","         [-0.2660,  0.1138,  0.0391,  ..., -0.2147,  0.1574,  0.1868],\n","         [ 0.0352, -0.0645,  0.1158,  ..., -0.3860,  0.2272, -0.0458]]],\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7816,  0.4299,  0.9999,  ...,  1.0000, -0.8020,  0.9917],\n","        [-0.7958,  0.4642,  0.9999,  ...,  1.0000, -0.7085,  0.9917],\n","        [-0.7565,  0.4065,  0.9998,  ...,  0.9999, -0.7253,  0.9869]],\n","       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"]}],"source":["new_bert_model=BertModel.from_pretrained(\"bert-base-cased\", num_hidden_layers= 12, pad_token_id= -1)\n","output=new_bert_model(**input)\n","print(output)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:18.855636Z","iopub.status.busy":"2025-05-27T09:50:18.855362Z","iopub.status.idle":"2025-05-27T09:50:19.321073Z","shell.execute_reply":"2025-05-27T09:50:19.320379Z","shell.execute_reply.started":"2025-05-27T09:50:18.855619Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4253,  0.3248,  0.0430,  ..., -0.2575,  0.3103,  0.1707],\n","         [ 0.5382, -0.1613,  0.6989,  ..., -0.0964, -0.0568,  0.3808],\n","         [ 0.2170,  0.2973,  0.5711,  ..., -0.2103,  0.0724,  0.7651],\n","         ...,\n","         [ 0.5229,  0.6780,  0.5030,  ..., -0.0231,  0.4312,  0.1336],\n","         [ 0.0116,  0.4218,  0.1210,  ...,  0.2599,  0.1712,  0.2193],\n","         [-0.0762,  0.2327,  0.3460,  ...,  0.0439,  0.3603,  0.1510]],\n","\n","        [[ 0.6200,  0.2703, -0.0238,  ..., -0.2052,  0.2143,  0.2290],\n","         [ 0.4604, -0.3071,  0.6603,  ..., -0.2155,  0.2643,  0.4050],\n","         [ 0.1338,  0.3411,  0.2855,  ..., -0.0541, -0.2121,  0.4941],\n","         ...,\n","         [ 0.1254,  0.1800,  0.6234,  ...,  0.3937,  0.0403,  0.1280],\n","         [ 0.7558,  1.1082, -0.0067,  ..., -0.0597,  0.1057, -0.0213],\n","         [ 0.6842,  1.1525,  0.0021,  ..., -0.0347,  0.0960,  0.0695]],\n","\n","        [[ 0.3652,  0.1974, -0.1084,  ..., -0.2368,  0.1061,  0.1169],\n","         [ 0.2221, -0.4938,  0.5226,  ..., -0.1244, -0.0099,  0.2656],\n","         [-0.1185,  0.3595,  0.0441,  ..., -0.0539, -0.1705,  0.0875],\n","         ...,\n","         [-0.3045,  0.3797, -0.0865,  ...,  0.1314,  0.0196,  0.3383],\n","         [-0.2660,  0.1138,  0.0391,  ..., -0.2147,  0.1574,  0.1868],\n","         [ 0.0352, -0.0645,  0.1158,  ..., -0.3860,  0.2272, -0.0458]]],\n","       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7816,  0.4299,  0.9999,  ...,  1.0000, -0.8020,  0.9917],\n","        [-0.7958,  0.4642,  0.9999,  ...,  1.0000, -0.7085,  0.9917],\n","        [-0.7565,  0.4065,  0.9998,  ...,  0.9999, -0.7253,  0.9869]],\n","       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"]}],"source":["bert_model=AutoModel.from_pretrained(\"bert-base-cased\")\n","new_output=bert_model(**input)\n","print(new_output)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:19.322094Z","iopub.status.busy":"2025-05-27T09:50:19.321833Z","iopub.status.idle":"2025-05-27T09:50:21.434682Z","shell.execute_reply":"2025-05-27T09:50:21.433967Z","shell.execute_reply.started":"2025-05-27T09:50:19.322072Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[[ 0.4253,  0.3248,  0.0430,  ..., -0.2575,  0.3103,  0.1707],\n","         [ 0.5382, -0.1613,  0.6989,  ..., -0.0964, -0.0568,  0.3808],\n","         [ 0.2170,  0.2973,  0.5711,  ..., -0.2103,  0.0724,  0.7651],\n","         ...,\n","         [ 0.5229,  0.6780,  0.5030,  ..., -0.0231,  0.4312,  0.1336],\n","         [ 0.0116,  0.4218,  0.1210,  ...,  0.2599,  0.1712,  0.2193],\n","         [-0.0762,  0.2327,  0.3460,  ...,  0.0439,  0.3603,  0.1510]],\n","\n","        [[ 0.6200,  0.2703, -0.0238,  ..., -0.2052,  0.2143,  0.2290],\n","         [ 0.4604, -0.3071,  0.6603,  ..., -0.2155,  0.2643,  0.4050],\n","         [ 0.1338,  0.3411,  0.2855,  ..., -0.0541, -0.2121,  0.4941],\n","         ...,\n","         [ 0.1254,  0.1800,  0.6234,  ...,  0.3937,  0.0403,  0.1280],\n","         [ 0.7558,  1.1082, -0.0067,  ..., -0.0597,  0.1057, -0.0213],\n","         [ 0.6842,  1.1525,  0.0021,  ..., -0.0347,  0.0960,  0.0695]],\n","\n","        [[ 0.3652,  0.1974, -0.1084,  ..., -0.2368,  0.1061,  0.1169],\n","         [ 0.2221, -0.4938,  0.5226,  ..., -0.1244, -0.0099,  0.2656],\n","         [-0.1185,  0.3595,  0.0441,  ..., -0.0539, -0.1705,  0.0875],\n","         ...,\n","         [-0.3045,  0.3797, -0.0865,  ...,  0.1314,  0.0196,  0.3383],\n","         [-0.2660,  0.1138,  0.0391,  ..., -0.2147,  0.1574,  0.1868],\n","         [ 0.0352, -0.0645,  0.1158,  ..., -0.3860,  0.2272, -0.0458]]],\n","       grad_fn=<NativeLayerNormBackward0>)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["new_output.last_hidden_state"]},{"cell_type":"markdown","metadata":{"id":"q6wwDwfUE9CC"},"source":["### **Using a Transformer model for inference**"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:21.436135Z","iopub.status.busy":"2025-05-27T09:50:21.435581Z","iopub.status.idle":"2025-05-27T09:50:22.164070Z","shell.execute_reply":"2025-05-27T09:50:22.163456Z","shell.execute_reply.started":"2025-05-27T09:50:21.436111Z"},"trusted":true},"outputs":[],"source":["bert_model.save_pretrained(\"/content/bert_model\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:22.165151Z","iopub.status.busy":"2025-05-27T09:50:22.164896Z","iopub.status.idle":"2025-05-27T09:50:22.169283Z","shell.execute_reply":"2025-05-27T09:50:22.168564Z","shell.execute_reply.started":"2025-05-27T09:50:22.165130Z"},"trusted":true},"outputs":[],"source":["sequences = [\"Hello!\", \"Cool\", \"Nice!\"]\n","\n","encoded_sequences = [\n","    [101, 7592, 999, 102],\n","    [101, 4658, 1012, 102],\n","    [101, 3835, 999, 102],\n","]"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:22.170355Z","iopub.status.busy":"2025-05-27T09:50:22.169982Z","iopub.status.idle":"2025-05-27T09:50:22.573251Z","shell.execute_reply":"2025-05-27T09:50:22.572536Z","shell.execute_reply.started":"2025-05-27T09:50:22.170330Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 101, 7592,  999,  102],\n","        [ 101, 4658, 1012,  102],\n","        [ 101, 3835,  999,  102]])\n"]}],"source":["import torch\n","new_input=torch.tensor(encoded_sequences)\n","print(new_input)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:22.574269Z","iopub.status.busy":"2025-05-27T09:50:22.574016Z","iopub.status.idle":"2025-05-27T09:50:25.522640Z","shell.execute_reply":"2025-05-27T09:50:25.521907Z","shell.execute_reply.started":"2025-05-27T09:50:22.574251Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"677d22e666b44f46926efac7437e3c23","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c44dfdc306034a37b4348db3ad8a1d43","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model=AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:25.523669Z","iopub.status.busy":"2025-05-27T09:50:25.523459Z","iopub.status.idle":"2025-05-27T09:50:25.607796Z","shell.execute_reply":"2025-05-27T09:50:25.607104Z","shell.execute_reply.started":"2025-05-27T09:50:25.523654Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["SequenceClassifierOutput(loss=None, logits=tensor([[-0.0491,  0.6652],\n","        [ 0.1415,  0.0104],\n","        [-0.0512,  0.6788]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"]}],"source":["google_bert_output=model(new_input)\n","print(google_bert_output)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:25.608724Z","iopub.status.busy":"2025-05-27T09:50:25.608502Z","iopub.status.idle":"2025-05-27T09:50:25.614717Z","shell.execute_reply":"2025-05-27T09:50:25.613987Z","shell.execute_reply.started":"2025-05-27T09:50:25.608687Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-0.0491,  0.6652],\n","        [ 0.1415,  0.0104],\n","        [-0.0512,  0.6788]], grad_fn=<AddmmBackward0>)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["google_bert_output.logits"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:25.618468Z","iopub.status.busy":"2025-05-27T09:50:25.618259Z","iopub.status.idle":"2025-05-27T09:50:25.631653Z","shell.execute_reply":"2025-05-27T09:50:25.631016Z","shell.execute_reply.started":"2025-05-27T09:50:25.618446Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.3287, 0.6713],\n","        [0.5327, 0.4673],\n","        [0.3252, 0.6748]], grad_fn=<SoftmaxBackward0>)\n"]}],"source":["probabilities=torch.nn.functional.softmax(google_bert_output.logits, dim=-1)\n","print(probabilities)"]},{"cell_type":"markdown","metadata":{"id":"bkm4zdXdcKrm"},"source":["## **Tokenizers**"]},{"cell_type":"markdown","metadata":{"id":"MxqIYZ6Adm5V"},"source":["### **Word Tokenize**"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:25.632725Z","iopub.status.busy":"2025-05-27T09:50:25.632488Z","iopub.status.idle":"2025-05-27T09:50:25.645374Z","shell.execute_reply":"2025-05-27T09:50:25.644633Z","shell.execute_reply.started":"2025-05-27T09:50:25.632687Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[\"I'm\", 'doing', 'Datascience', 'and', 'ai', 'projects,', 'and', 'now', 'a', 'days', \"I'm\", 'doing', 'NLP', 'course']\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","tokenize_text=\"I'm doing Datascience and ai projects, and now a days I'm doing NLP course\"\n","text_tokenize=tokenize_text.split()\n","print(text_tokenize)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:25.646329Z","iopub.status.busy":"2025-05-27T09:50:25.646077Z","iopub.status.idle":"2025-05-27T09:50:27.702849Z","shell.execute_reply":"2025-05-27T09:50:27.702170Z","shell.execute_reply.started":"2025-05-27T09:50:25.646303Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90749d34416941889d2b63f56641b61f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48c31bf3f277402cb408589ef88dd021","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"896820d6280f415eaca5251038751bdc","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['I', \"'\", 'm', 'doing', 'Data', '##science', 'and', 'a', '##i', 'projects', ',', 'and', 'now', 'a', 'days', 'I', \"'\", 'm', 'doing', 'NL', '##P', 'course']\n"]}],"source":["tokenizer=AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","output_text=tokenizer.tokenize(tokenize_text)\n","print(output_text)"]},{"cell_type":"markdown","metadata":{"id":"qmGKBdIffipn"},"source":["### **Loading and saving**"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:27.703818Z","iopub.status.busy":"2025-05-27T09:50:27.703558Z","iopub.status.idle":"2025-05-27T09:50:28.180869Z","shell.execute_reply":"2025-05-27T09:50:28.180067Z","shell.execute_reply.started":"2025-05-27T09:50:27.703794Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["SequenceClassifierOutput(loss=None, logits=tensor([[-0.0356,  0.3950],\n","        [-0.1043,  0.4250],\n","        [-0.0993,  0.4622]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"]}],"source":["bert_base_model=AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n","output=bert_base_model(**input)\n","print(output)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:28.182055Z","iopub.status.busy":"2025-05-27T09:50:28.181775Z","iopub.status.idle":"2025-05-27T09:50:30.644227Z","shell.execute_reply":"2025-05-27T09:50:30.643543Z","shell.execute_reply.started":"2025-05-27T09:50:28.182033Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["key:  input_ids\n","value:  [101, 7993, 170, 13809, 23763, 2443, 1110, 3014, 102]\n","\n","key:  token_type_ids\n","value:  [0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n","key:  attention_mask\n","value:  [1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n"]}],"source":["outputs = tokenizer(\"Using a Transformer network is simple\")\n","for key,value in outputs.items():\n","  print(\"key: \", key)\n","  print(\"value: \", value, end=\"\\n\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["### **Save bert-base-cased Model**"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:30.645600Z","iopub.status.busy":"2025-05-27T09:50:30.645077Z","iopub.status.idle":"2025-05-27T09:50:31.355048Z","shell.execute_reply":"2025-05-27T09:50:31.354483Z","shell.execute_reply.started":"2025-05-27T09:50:30.645571Z"},"trusted":true},"outputs":[],"source":["bert_base_model.save_pretrained(\"/content/bert_base_new_model\")"]},{"cell_type":"markdown","metadata":{"id":"SNL3gOQIgSrx"},"source":["### **Convert tokens to input ids**"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:31.356152Z","iopub.status.busy":"2025-05-27T09:50:31.355889Z","iopub.status.idle":"2025-05-27T09:50:31.360019Z","shell.execute_reply":"2025-05-27T09:50:31.359298Z","shell.execute_reply.started":"2025-05-27T09:50:31.356127Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[146, 112, 182, 1833, 7154, 22274, 1105, 170, 1182, 3203, 117, 1105, 1208, 170, 1552, 146, 112, 182, 1833, 21239, 2101, 1736]\n"]}],"source":["ids=tokenizer.convert_tokens_to_ids(output_text)\n","print(ids)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:31.361087Z","iopub.status.busy":"2025-05-27T09:50:31.360797Z","iopub.status.idle":"2025-05-27T09:50:31.374460Z","shell.execute_reply":"2025-05-27T09:50:31.373754Z","shell.execute_reply.started":"2025-05-27T09:50:31.361067Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["I ' m doing Datascience and ai projects, and now a days I ' m doing NLP course\n"]}],"source":["decode_ids=tokenizer.decode([146, 112, 182, 1833, 7154, 22274, 1105, 170, 1182, 3203, 117, 1105, 1208, 170, 1552, 146, 112, 182, 1833, 21239, 2101, 1736])\n","print(decode_ids)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:31.375363Z","iopub.status.busy":"2025-05-27T09:50:31.375174Z","iopub.status.idle":"2025-05-27T09:50:31.386069Z","shell.execute_reply":"2025-05-27T09:50:31.385503Z","shell.execute_reply.started":"2025-05-27T09:50:31.375341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["IDs:  [146, 112, 182, 1833, 7154, 22274, 1105, 170, 1182, 3203, 117, 1105, 1208, 170, 1552, 146, 112, 182, 1833, 21239, 2101, 1736]\n","Input IDs:  [[101, 146, 102], [101, 112, 102], [101, 182, 102], [101, 1833, 102], [101, 7154, 102], [101, 108, 108, 2598, 102], [101, 1105, 102], [101, 170, 102], [101, 108, 108, 178, 102], [101, 3203, 102], [101, 117, 102], [101, 1105, 102], [101, 1208, 102], [101, 170, 102], [101, 1552, 102], [101, 146, 102], [101, 112, 102], [101, 182, 102], [101, 1833, 102], [101, 21239, 102], [101, 108, 108, 153, 102], [101, 1736, 102]]\n"]}],"source":["print(\"IDs: \", ids)\n","print(\"Input IDs: \", tokenizer(output_text)[\"input_ids\"])"]},{"cell_type":"markdown","metadata":{"id":"otkFUo1IiyXH"},"source":["### **convert ids to tokens**"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:31.386892Z","iopub.status.busy":"2025-05-27T09:50:31.386674Z","iopub.status.idle":"2025-05-27T09:50:31.399046Z","shell.execute_reply":"2025-05-27T09:50:31.398489Z","shell.execute_reply.started":"2025-05-27T09:50:31.386879Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['I',\n"," \"'\",\n"," 'm',\n"," 'doing',\n"," 'Data',\n"," '##science',\n"," 'and',\n"," 'a',\n"," '##i',\n"," 'projects',\n"," ',',\n"," 'and',\n"," 'now',\n"," 'a',\n"," 'days',\n"," 'I',\n"," \"'\",\n"," 'm',\n"," 'doing',\n"," 'NL',\n"," '##P',\n"," 'course']"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.convert_ids_to_tokens([146, 112, 182, 1833, 7154, 22274, 1105, 170, 1182, 3203, 117, 1105, 1208, 170, 1552, 146, 112, 182, 1833, 21239, 2101, 1736])"]},{"cell_type":"markdown","metadata":{},"source":["### **Summing Up All Together**"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:31.400067Z","iopub.status.busy":"2025-05-27T09:50:31.399786Z","iopub.status.idle":"2025-05-27T09:50:31.928883Z","shell.execute_reply":"2025-05-27T09:50:31.928173Z","shell.execute_reply.started":"2025-05-27T09:50:31.400050Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['i', \"'\", 've', 'been', 'waiting', 'for', 'a', 'hugging', '##face', 'course', 'my', 'whole', 'life', '.', 'i', 'have', 'learned', 'a', 'lot', 'from', 'this', 'course', '!']\n","[1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 1045, 2031, 4342, 1037, 2843, 2013, 2023, 2607, 999]\n","tensor([ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n","         2026,  2878,  2166,  1012,  1045,  2031,  4342,  1037,  2843,  2013,\n","         2023,  2607,   999])\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n","checkpoint=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model=AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","raw_inputs=[\n","    \"I've been waiting for a HuggingFace course my whole life.\",\n","    \"I have learned a lot from this course!\",\n","]\n","inputs=tokenizer.tokenize(raw_inputs)\n","print(inputs)\n","# convert tokens to ids\n","ids = tokenizer.convert_tokens_to_ids(inputs)\n","print(ids)\n","input_ids=torch.tensor(ids)\n","print(input_ids)"]},{"cell_type":"markdown","metadata":{},"source":["### **Performing Inference with istilbert-base-uncased-finetuned-sst-2-english Pre-trained Model**"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:31.929843Z","iopub.status.busy":"2025-05-27T09:50:31.929581Z","iopub.status.idle":"2025-05-27T09:50:32.507428Z","shell.execute_reply":"2025-05-27T09:50:32.506644Z","shell.execute_reply.started":"2025-05-27T09:50:31.929817Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-1.5607,  1.6123],\n","        [-2.9620,  3.0196]], grad_fn=<AddmmBackward0>)\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","checkpoint = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","\n","raw_inputs = [\n","    \"I've been waiting for a HuggingFace course my whole life.\",\n","    \"I have learned a lot from this course!\",\n","]\n","\n","# Proper tokenization with batching\n","inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n","\n","output=model(**inputs)\n","\n","# Output logits\n","print(output.logits)\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:32.508545Z","iopub.status.busy":"2025-05-27T09:50:32.508264Z","iopub.status.idle":"2025-05-27T09:50:32.837276Z","shell.execute_reply":"2025-05-27T09:50:32.836551Z","shell.execute_reply.started":"2025-05-27T09:50:32.508517Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"name":"stdout","output_type":"stream","text":["SequenceClassifierOutput(loss=None, logits=tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","SequenceClassifierOutput(loss=None, logits=tensor([[ 1.5694, -1.3895],\n","        [ 1.3373, -1.2163]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","SequenceClassifierOutput(loss=None, logits=tensor([[ 1.5694, -1.3895],\n","        [ 0.9907, -0.9139]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"]}],"source":["padding_id=100\n","batched_id=[[200,200,200],\n","            [200,200,padding_id]]\n","checkpoint = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n","model=AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","sequence_1_ids=[[200,200,200]]\n","sequence_2_ids=[[200,200,200],\n","            [200,200,tokenizer.pad_token_id]]\n","print(model(torch.tensor(sequence_1_ids)))\n","print(model(torch.tensor(sequence_2_ids)))\n","print(model(torch.tensor(batched_id)))\n","\n","\n"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:32.838407Z","iopub.status.busy":"2025-05-27T09:50:32.838148Z","iopub.status.idle":"2025-05-27T09:50:32.844498Z","shell.execute_reply":"2025-05-27T09:50:32.843890Z","shell.execute_reply.started":"2025-05-27T09:50:32.838385Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[  101,  1045,  2074,  2949,  2026,  2034, 17953,  2361,  2944,  4283,\n","          2000,  2023,  2607,  1010,  1998,  2009,  5683,  6429,   999,   102,\n","             0,     0],\n","        [  101,  2023,  2607,  2003, 14336,  2061,  2092,  1010,  2009,  1005,\n","          1055,  1996,  2190,  4083,  3325,  1045,  1005,  2310,  2018,  3784,\n","          1012,   102],\n","        [  101,  1996,  6393,  2003,  2205,  3435,  1010,  1998,  1045,  2514,\n","          3294,  2439,  2044,  1996,  2034,  2261,  8220,  1012,   102,     0,\n","             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n"]}],"source":["text_sequence=[\"I'm doing Huggig Face course\",\n","               \"It's content is very good\"]\n","input=tokenizer(raw_text, padding=True, truncation=True, return_tensors=\"pt\")\n","print(input)"]},{"cell_type":"markdown","metadata":{},"source":["### **Check Attention Mask and Input ids**"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:32.845768Z","iopub.status.busy":"2025-05-27T09:50:32.845285Z","iopub.status.idle":"2025-05-27T09:50:32.856453Z","shell.execute_reply":"2025-05-27T09:50:32.855893Z","shell.execute_reply.started":"2025-05-27T09:50:32.845750Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["input_ids\n","tensor([[  101,  1045,  2074,  2949,  2026,  2034, 17953,  2361,  2944,  4283,\n","          2000,  2023,  2607,  1010,  1998,  2009,  5683,  6429,   999,   102,\n","             0,     0],\n","        [  101,  2023,  2607,  2003, 14336,  2061,  2092,  1010,  2009,  1005,\n","          1055,  1996,  2190,  4083,  3325,  1045,  1005,  2310,  2018,  3784,\n","          1012,   102],\n","        [  101,  1996,  6393,  2003,  2205,  3435,  1010,  1998,  1045,  2514,\n","          3294,  2439,  2044,  1996,  2034,  2261,  8220,  1012,   102,     0,\n","             0,     0]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n","tensor([[  101,  1045,  2074,  2949,  2026,  2034, 17953,  2361,  2944,  4283,\n","          2000,  2023,  2607,  1010,  1998,  2009,  5683,  6429,   999,   102,\n","             0,     0],\n","        [  101,  2023,  2607,  2003, 14336,  2061,  2092,  1010,  2009,  1005,\n","          1055,  1996,  2190,  4083,  3325,  1045,  1005,  2310,  2018,  3784,\n","          1012,   102],\n","        [  101,  1996,  6393,  2003,  2205,  3435,  1010,  1998,  1045,  2514,\n","          3294,  2439,  2044,  1996,  2034,  2261,  8220,  1012,   102,     0,\n","             0,     0]])\n","attention_mask\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n","tensor([[  101,  1045,  2074,  2949,  2026,  2034, 17953,  2361,  2944,  4283,\n","          2000,  2023,  2607,  1010,  1998,  2009,  5683,  6429,   999,   102,\n","             0,     0],\n","        [  101,  2023,  2607,  2003, 14336,  2061,  2092,  1010,  2009,  1005,\n","          1055,  1996,  2190,  4083,  3325,  1045,  1005,  2310,  2018,  3784,\n","          1012,   102],\n","        [  101,  1996,  6393,  2003,  2205,  3435,  1010,  1998,  1045,  2514,\n","          3294,  2439,  2044,  1996,  2034,  2261,  8220,  1012,   102,     0,\n","             0,     0]])\n"]}],"source":["for key in input:\n","  print(key)\n","  print(input[key])\n","  print(input['attention_mask'])\n","  print(input['input_ids'])"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:32.857397Z","iopub.status.busy":"2025-05-27T09:50:32.857167Z","iopub.status.idle":"2025-05-27T09:50:32.867190Z","shell.execute_reply":"2025-05-27T09:50:32.866501Z","shell.execute_reply.started":"2025-05-27T09:50:32.857374Z"},"trusted":true},"outputs":[{"data":{"text/plain":["512"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.model_max_length"]},{"cell_type":"markdown","metadata":{},"source":["### **Padding**"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2025-05-27T09:50:32.868391Z","iopub.status.busy":"2025-05-27T09:50:32.867936Z","iopub.status.idle":"2025-05-27T09:50:32.880322Z","shell.execute_reply":"2025-05-27T09:50:32.879606Z","shell.execute_reply.started":"2025-05-27T09:50:32.868375Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[101, 1045, 1005, 1049, 2725, 8549, 5856, 2290, 2227, 2607, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2009, 1005, 1055, 4180, 2003, 2200, 2204, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n","{'input_ids': [[101, 1045, 1005, 1049, 2725, 8549, 5856, 2290, 2227, 2607, 102], [101, 2009, 1005, 1055, 4180, 2003, 2200, 2204, 102, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]}\n","{'input_ids': [[101, 1045, 1005, 1049, 2725, 8549, 5856, 2290, 2227, 2607, 102], [101, 2009, 1005, 1055, 4180, 2003, 2200, 2204, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}],"source":["new_model_input=tokenizer(text_sequence, padding=\"max_length\")\n","print(new_model_input)\n","new_model_input_1=tokenizer(text_sequence, padding=\"longest\")\n","print(new_model_input_1)\n","new_model_input_2=tokenizer(text_sequence, padding=\"max_length\", max_length=8)\n","print(new_model_input_2)"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
